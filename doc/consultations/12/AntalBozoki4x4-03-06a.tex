\documentclass{article}
\usepackage[latin1]{inputenc}
\usepackage{amssymb, amsmath, amsthm}
\usepackage[a4paper]{geometry}

%\usepackage{authblk} % for headings
%\usepackage{pifont}
%\usepackage{graphicx}
%\usepackage{xtab} % tackle the long tables
%\usepackage{longtable} % tackle the long tables
\usepackage{footnote}
\makesavenoteenv{tabular}
\usepackage{tabularx}
%\usepackage{tabu}
\usepackage{rotating}

\def\url#1{\expandafter\string\csname #1\endcsname}

\usepackage{enumitem}
\usepackage{color}
\usepackage{amsmath}% http://ctan.org/pkg/amsmath
\newcommand{\abs}[1]{\lvert#1\rvert}
\newcommand{\Abs}[1]{\left\lvert#1\right\rvert}

% \highlight[<colour>]{<stuff>}
\newcommand{\highlight}[2][yellow]{\mathchoice%
  {\colorbox{#1}{$\displaystyle#2$}}%
  {\colorbox{#1}{$\textstyle#2$}}%
  {\colorbox{#1}{$\scriptstyle#2$}}%
  {\colorbox{#1}{$\scriptscriptstyle#2$}}}%
%-----------------------------------------------------------

\theoremstyle{plain}
\newtheorem{conjecture}{Conjecture}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]
\newtheorem*{example*}{Example}
\newtheorem{lemma}{Lemma}[section]
\newtheorem{problem}{Problem}
\newtheorem{openproblem}{Open problem}
\newtheorem{proposition}{Proposition}[section]
\newtheorem{remark}{Remark}
\newtheorem{theorem}{Theorem}[section]
\newcommand{\aproof}{\hfill{\ding{111}}}

\def\keywords{\vspace{.5em} % Add keywords
{\textit{Keywords}:\,\relax%
}}
\def\endkeywords{\par}

\usepackage{color}
\definecolor{gr}{rgb}{0,0.5,0}
\usepackage{hyperref}
%\usepackage{url}



\begin{document}

\begin{center}
\color{red}
\textbf{Please print carefully. The paper on the f{\kern0pt}irst 8 pages is followed by an extremely long appendix.} \\[2cm]
\color{black}
\end{center}



\begin{center}
\Large{Ef{\kern0pt}f{\kern0pt}iciency test of priority vectors derived from $4\times4$ pairwise comparison matrices} \\
\end{center}

\begin{center}
\'Ad\'am ANTAL$^{\,\,1}$,
\footnotetext[1]{Eötvös Loránd University (ELTE), Budapest, Hungary \textit{E-mail: antaladam@yahoo.com}}
S\'andor BOZ\'OKI$^{\,\,2,3,4}$
\footnotetext[2]{Laboratory on Engineering and Management
Intelligence, Research Group of Operations Research and Decision
Systems, Institute for Computer Science and Control, Hungarian
Academy of Sciences (MTA SZTAKI); Mail: 1518 Budapest, P.O.~Box 63, Hungary.}
\footnotetext[3]{Department of Operations Research and Actuarial Sciences, Corvinus University
of Budapest, Hungary
 \textit{E-mail: bozoki.sandor@sztaki.mta.hu}}
 \footnotetext[4]{corresponding author}

\end{center}
\begin{abstract}
Three weighting methods, the eigenvector, the arithmetic mean of all spanning trees' weight vectors (AMAST) and the
cosine maximization have been investigated in case of $4 \times 4$ pairwise comparison matrices,
with elements chosen from the usual ratio scale $1,2,\ldots,9,1/2,$ $1/3,\ldots,1/9$.
Out of the $32\,157$ permutation f{\kern0pt}iltered matrices fulf{\kern0pt}illing the rule of acceptable inconsistency ($CR \leq 0.1$),
591 (1.84\%); 197 (0.61\%) and 602 (1.87\%) have inef{\kern0pt}f{\kern0pt}icient eigenvector, AMAST and cosine maximizing weight vector,
respectively. All these examples are listed in the appendix.

\keywords{multiple criteria analysis, decision support, pairwise comparison matrix, Pareto
optimality, ef{\kern0pt}f{\kern0pt}iciency, eigenvector, spanning trees, cosine similarity}
\end{abstract}
\section{Introduction} \label{section:1} % \ref{section:1}
\label{intro}


\subsection{Ef{\kern0pt}f{\kern0pt}iciency of weight vectors derived from pairwise comparison matrices}

Preference modelling, especially the quantif{\kern0pt}ication of decision maker's preferences
is fundamental in decision theory and decision support. We focus on decision models based
on cardinal information originated from comparisons of two objects at a time.
A positive and reciprocal ($a_{ij}=1/a_{ji}$ for all $i,j$) matrix
is called a pairwise comparison matrix \cite{Saaty1977}. The matrix element $a_{ij}$ ref{\kern0pt}lects the decision maker's
preference on a ratio scale when item (typically the importance of a criterion, or the performance of action) $i$ is
compared to item $j$.


Let $\mathbf{A}$ be a pairwise comparison matrix of size $n \times n$
and $\mathbf{w}, \mathbf{w^{\prime}} \in \mathbb{R}^n$ be positive weight vectors.


\begin{definition} \label{def:DefinitionEfficient}  % \ref{def:DefinitionEfficient}
Weight vector $\mathbf{w^{\prime}} = (w^{\prime}_1, w^{\prime}_2, \ldots, w^{\prime}_n)^{\top}$
\emph{dominates} weight vector $\mathbf{w}$ if
\begin{align}
 \left|a_{ij} - \frac{w^{\prime}_i}{w^{\prime}_j} \right| &\leq \left|a_{ij} - \frac{w_i}{w_j} \right| \qquad \text{ for all } 1 \leq i,j \leq n, \label{def:DefinitionEfficientProperty1}  \\   %(\ref{def:DefinitionEfficientProperty1})
 \left|a_{k{\ell}} - \frac{w^{\prime}_k}{w^{\prime}_{\ell}} \right| &<  \left|a_{k{\ell}} - \frac{w_k}{w_{\ell}} \right|  \qquad \text{ for some } 1 \leq k,\ell \leq n.  \label{def:DefinitionEfficientProperty2}    %(\ref{def:DefinitionEfficientProperty2})
\end{align}
\end{definition}

If weight vector $\mathbf{w}$ cannot be dominated, then it is called \emph{ef{\kern0pt}f{\kern0pt}icient},
otherwise it is called \emph{inef{\kern0pt}f{\kern0pt}icient}.

\begin{definition} \label{def:DefinitionInternallyEfficient} %(\ref{def:DefinitionInternallyEfficient})
Weight vector $\mathbf{w^{\prime}} = (w^{\prime}_1, w^{\prime}_2, \ldots, w^{\prime}_n)^{\top}$
\emph{internally} dominates weight vector $\mathbf{w}$ if
\begin{align}
\left.
\begin{array}{ccc}
a_{ij} \leq \frac{w_i}{w_j} & \Longrightarrow &
a_{ij} \leq \frac{w^{\prime}_i}{w^{\prime}_j} \leq \frac{w_i}{w_j} \\
a_{ij} \geq \frac{w_i}{w_j} & \Longrightarrow &
a_{ij} \geq \frac{w^{\prime}_i}{w^{\prime}_j} \geq \frac{w_i}{w_j}
\end{array}
\right\}
\qquad
\text{ for all } 1 \leq i,j \leq n, \label{def:DefinitionInternallyEfficientProperty1}  \\   %(\ref{def:DefinitionInternallyEfficientProperty1})
\left.
\begin{array}{ccc}
a_{k{\ell}} \leq \frac{w_k}{w_{\ell}} & \Longrightarrow &
\frac{w^{\prime}_k}{w^{\prime}_{\ell}} < \frac{w_k}{w_{\ell}} \\
a_{k{\ell}} \geq \frac{w_k}{w_{\ell}} & \Longrightarrow &
\frac{w^{\prime}_k}{w^{\prime}_{\ell}} > \frac{w_k}{w_{\ell}}
\end{array}
\right\}
\qquad
\text{ for some } 1 \leq k,\ell \leq n.  \label{def:DefinitionInternallyEfficientProperty2}    %(\ref{def:DefinitionInternallyEfficientProperty2})
\end{align}
\end{definition}
If weight vector $\mathbf{w}$ cannot be internally dominated, then it is called
\emph{internally ef{\kern0pt}f{\kern0pt}icient}, otherwise it is called \emph{internally inef{\kern0pt}f{\kern0pt}icient}.

Ef{\kern0pt}f{\kern0pt}iciency implies internal ef{\kern0pt}f{\kern0pt}iciency by def{\kern0pt}inition, but they are in fact equivalent
\cite[Corollary 1]{BozokiFulop2018}.
Def{\kern0pt}initions also imply that ef{\kern0pt}f{\kern0pt}iciency is scale invariant:
weight vector $\mathbf{w}$ is ef{\kern0pt}f{\kern0pt}icient if and only if $c\mathbf{w}$ is ef{\kern0pt}f{\kern0pt}icient, where $c > 0$
is arbitrary. Ratios $\frac{w_i}{w_j}$ and $\frac{cw_i}{cw_j}$ are clearly equal.

A dominating weight vector $\mathbf{w}^{\prime}$, if it exists,  can be found by solving
the following linear program, developed by Boz\'oki and F\"ul\"op \cite[formulas (26)-(31)]{BozokiFulop2018}:

\begin{align}
\min  \sum\limits_{(i,j): a_{ij} < \frac{w_i}{w_j} } - s_{ij}
     &  &  \label{LP1}  \\
y_j - y_i  & \leq - \log a_{ij}    &\text{ for all $(i,j)$ such that $ a_{ij} < \frac{w_i}{w_j}$ ,} \label{LP2}  \\
y_i - y_j + s_{ij} & \leq  \log w_i - \log w_j  &\text{ for all $(i,j)$ such that $ a_{ij} < \frac{w_i}{w_j}$ ,} \label{LP3} \\
y_i - y_j  & = \log a_{ij}    &\text{ for all $(i,j)$ such that $ a_{ij} = \frac{w_i}{w_j}$ ,} \label{LP4} \\
s_{ij}  & \geq 0  &\text{ for all $(i,j)$ such that $ a_{ij} < \frac{w_i}{w_j}$ ,} \label{LP5} \\
                   y_1 & = 0    & \label{LP6}
\end{align}
Variables are $y_i, \,  1 \leq i \leq n$ and $s_{ij}$ for all $(i,j)$ such that $ a_{ij} < \frac{w_i}{w_j}$.

According to Theorem 4.1 in \cite{BozokiFulop2018},
the optimum value of the linear program (\ref{LP1})-(\ref{LP6}) is 0
if and only if weight vector $\mathbf{w}$ is ef{\kern0pt}f{\kern0pt}icient.
Let $(\mathbf{y}^{\ast},\mathbf{s}^{\ast})$ denote the optimal solution to (\ref{LP1})-(\ref{LP6}).
If weight vector $\mathbf{w}$ is inef{\kern0pt}f{\kern0pt}icient, then
weight vector $\mathbf{w}^{\prime}=\exp({\mathbf{y}}^{\ast})$
is ef{\kern0pt}f{\kern0pt}icient and dominates $\mathbf{w}$ internally.

\subsection{Weighting methods}

Several weighting methods have been proposed to f{\kern0pt}ind a weight vector $\mathbf{w}$
from a pairwise comparison matrix $\mathbf{A}$. An inevitably oversimplif{\kern0pt}ied conclusion of the comprehensive studies of
Golany and Kress \cite{GolanyKress1993},
Choo and Wedley \cite{ChooWedley2004},
Lin \cite{Lin2007},
Bajwa, Choo and Wedley \cite{BajwaChooWedley2008},
Fedrizzi and Brunelli \cite{FedrizziBrunelli2010},
is that there is no universal weighting method that outperforms the others.

Several distance minimizing methods, such as the least squares method,
where the metric is strictly monotonic \cite{Fedrizzi2013}, always result in ef{\kern0pt}f{\kern0pt}icient weight vectors.
Interestingly, not all distance minimizing methods generate ef{\kern0pt}f{\kern0pt}icient weights. The most remarkable
example is the eigenvector method, deriving weight from the principal right eigenvector of $\mathbf{A}$,
which minimizes a special (neither continuous, nor strictly monotonic)
 metric found by Fichtner \cite{Fichtner1984,Fichtner1986}.
Blanquero, Carrizosa and Conde \cite{BlanqueroCarrizosaConde2006} observed f{\kern0pt}irst that the eigenvector is not
always ef{\kern0pt}f{\kern0pt}icient. However, a necessary and suf{\kern0pt}f{\kern0pt}icient condition of the ef{\kern0pt}f{\kern0pt}iciency of the eigenvector has not been
found.

We show that another two weighting methods, namely the arithmetic mean of weight vectors
calculated from all spanning trees and the weight vector calculated by the cosine maximization method
can also be inef{\kern0pt}f{\kern0pt}icient. The spanning tree approach was proposed by Tsyganok \cite{Tsyganok2000,Tsyganok2010}.
It takes into account all the connected subsets of cardinality $n-1$ of the set of all comparisons, i.e., all the
$n^{n-2}$ spanning trees if the matrix elements are represented by edges in a graph on $n$ vertices.
Every spanning tree determines a unique weight vector, and two natural ways of their aggregation are the
arithmetic mean \cite{SirajMikhailovKeane2012a,SirajMikhailovKeane2012b,Tsyganok2000,Tsyganok2010}, denoted here by
AMAST (arithmetic mean of all spanning tree weight vectors), and the geometric mean
\cite{LundySirajGreco2017,BozokiTsyganok2018}. However, the geometric mean of all spanning tree weight vectors
has recently been proved to be equivalent to the
Logarithmic Least Squares Method \cite{CrawfordWilliams1980,CrawfordWilliams1985,deGraan1980,Rabinowitz1976}, which always
provides an ef{\kern0pt}f{\kern0pt}icient weight vector \cite[Corollary 7]{BlanqueroCarrizosaConde2006}.
The eigenvector and the logarithmic least squares method are equivalent for $3 \times 3$ pairwise
comparison matrices \cite{CrawfordWilliams1980,CrawfordWilliams1985}. Consequently, the smallest
matrix size, when the eigenvector can be inef{\kern0pt}f{\kern0pt}icient, is $4 \times 4.$

The cosine maximization method \cite{KouLin2014} is based on a geometric intuition of
that vectors can be considered similar to each other if their angle is small (cosine of the angle is high),
or, equivalently, their dot product is high. The simply computable and unique weight
vector \cite[Theorem 2]{KouLin2014}, denoted
by $\mathbf{w}^{\cos}$, maximizes the sum of cosine similarity measure for all column vectors of the pairwise
comparison matrix. Despite the geometric intuition behind, weight vector $\mathbf{w}^{\cos}$ can be inef{\kern0pt}f{\kern0pt}icient
as it is presented in the next section.



\section{Results} \label{section:2} % \ref{section:2}


There are $1\,007\,097$ pairwise comparison matrices of size $4 \times 4$ such that
all elements are from the ratio scale $1,2,\ldots,9,1/2,1/3,\ldots,1/9$,
and no pair of matrices can be transformed into each other by row/column permutations
(without permutation f{\kern0pt}iltering there would be $17^6 = 24\,137\,569$ matrices).

\subsection{Matrices with acceptable inconsistency ($CR \leq 0.1$)}
The $CR$ inconsistency is below $0.1$ \cite{Saaty1977} for $32\,157$ out of all
permutation f{\kern0pt}iltered matrices, resulting in a ratio 3.19\%.
It is similar to the frequency 3.15\% experienced by Boz\'oki and Rapcs\'ak \cite[Table 4]{BozokiRapcsak2008},
although their matrices were generated randomly.

Out of the $32\,157$ permutation f{\kern0pt}iltered matrices fulf{\kern0pt}illing $CR \leq 0.1$,
\begin{itemize}
\item 591 (1.84\%) have inef{\kern0pt}f{\kern0pt}icient eigenvector;
\item 197 (0.61\%) have inef{\kern0pt}f{\kern0pt}icient weight vector calculated by the spanning trees' arithmetic mean;
\item 602 (1.87\%) have inef{\kern0pt}f{\kern0pt}icient weight vector calculated by the cosine maximization method.
\end{itemize}

They are listed in the Appendix (Examples A.1--591, B.1--197, C.1--602, respectively),
an illustrative example is given below.

\begin{example*} (Example A.73 in the Appendix)
\begin{equation*}
\mathbf{A} =
\begin{pmatrix}
$\,\,$ 1 $\,\,$ & $\,\,$2$\,\,$ & $\,\,$6$\,\,$ & $\,\,$7 $\,\,$ \\
$\,\,$ 1/2$\,\,$ & $\,\,$ 1 $\,\,$ & $\,\,$5$\,\,$ & $\,\,$2 $\,\,$ \\
$\,\,$ 1/6$\,\,$ & $\,\,$ 1/5$\,\,$ & $\,\,$ 1 $\,\,$ & $\,\,$2 $\,\,$ \\
$\,\,$ 1/7$\,\,$ & $\,\,$ 1/2$\,\,$ & $\,\,$ 1/2$\,\,$ & $\,\,$ 1  $\,\,$ \\
\end{pmatrix},
\qquad
\lambda_{\max} =
4.2251,
\qquad
CR = 0.0849
\end{equation*}

\begin{equation*}
\mathbf{w}^{EM} =
\begin{pmatrix}
\color{red} 0.536063\color{black} \\
0.284402\\
0.096706\\
0.082830
\end{pmatrix}\end{equation*}
\begin{equation*}
\left[ \frac{{w}^{EM}_i}{{w}^{EM}_j} \right] =
\begin{pmatrix}
$\,\,$ 1 $\,\,$ & $\,\,$\color{red} 1.8849\color{black} $\,\,$ & $\,\,$\color{red} 5.5432\color{black} $\,\,$ & $\,\,$\color{red} 6.4718\color{black} $\,\,$ \\
$\,\,$\color{red} 0.5305\color{black} $\,\,$ & $\,\,$ 1 $\,\,$ & $\,\,$2.9409$\,\,$ & $\,\,$3.4336  $\,\,$ \\
$\,\,$\color{red} 0.1804\color{black} $\,\,$ & $\,\,$0.3400$\,\,$ & $\,\,$ 1 $\,\,$ & $\,\,$1.1675 $\,\,$ \\
$\,\,$\color{red} 0.1545\color{black} $\,\,$ & $\,\,$0.2912$\,\,$ & $\,\,$0.8565$\,\,$ & $\,\,$ 1  $\,\,$ \\
\end{pmatrix},
\end{equation*}

It can be seen that all non-diagonal elements of the f{\kern0pt}irst row/column are under/overestimated,
indicating that the eigenvector is inef{\kern0pt}f{\kern0pt}icient.
Indeed, the ef{\kern0pt}f{\kern0pt}icient and internally
dominating weight vector $\mathbf{w}^{\prime}$, found by (\ref{LP1})-(\ref{LP6}) is as follows:
\[
\mathbf{w}^{\prime} =
\begin{pmatrix}
0.550771\\
0.275385\\
0.093640\\
0.080204
\end{pmatrix}.
\]
Its relation to the eigenvector $\mathbf{w}^{EM}$ can be made more visible by an appropriate
rescaling
\begin{equation*}
\mathbf{w}^{\prime} =
0.968297\cdot
\begin{pmatrix}
\color{gr} 0.568803\color{black} \\
0.284402\\
0.096706\\
0.082830
\end{pmatrix},
\end{equation*}
which shows that the last three coordinates have not changed,
the f{\kern0pt}irst coordinate has been increased as we expected.
Furthermore, the f{\kern0pt}irst coordinate has been increased such that
$a_{12} = \frac{w^{\prime}_1}{w^{\prime}_2} = 2$, i.e., not only
$\left| \frac{w^{\prime}_1}{w^{\prime}_2} - a_{12} \right| <
 \left| \frac{w_1}{w_2} - a_{12} \right| $ holds but the left hand side of the inequality equals to zero.

\begin{equation*}
\left[ \frac{{w}^{\prime}_i}{{w}^{\prime}_j} \right] =
\begin{pmatrix}
$\,\,$ 1 $\,\,$ & $\,\,$\color{gr} \color{blue} 2\color{black} $\,\,$ & $\,\,$\color{gr} 5.8818\color{black} $\,\,$ & $\,\,$\color{gr} 6.8671\color{black} $\,\,$ \\
$\,\,$\color{gr} \color{blue}  1/2\color{black} $\,\,$ & $\,\,$ 1 $\,\,$ & $\,\,$2.9409$\,\,$ & $\,\,$3.4336  $\,\,$ \\
$\,\,$\color{gr} 0.1700\color{black} $\,\,$ & $\,\,$0.3400$\,\,$ & $\,\,$ 1 $\,\,$ & $\,\,$1.1675 $\,\,$ \\
$\,\,$\color{gr} 0.1456\color{black} $\,\,$ & $\,\,$0.2912$\,\,$ & $\,\,$0.8565$\,\,$ & $\,\,$ 1  $\,\,$ \\
\end{pmatrix},
\end{equation*}
\end{example*}

We would also like to draw the attention to a special example.
\begin{example}  (Example A.116 in the Appendix) % Example 1.116
\begin{equation*}
\mathbf{A} =
\begin{pmatrix}
$\,\,$ 1 $\,\,$ & $\,\,$2$\,\,$ & $\,\,$9$\,\,$ & $\,\,$8 $\,\,$ \\
$\,\,$ 1/2$\,\,$ & $\,\,$ 1 $\,\,$ & $\,\,$3$\,\,$ & $\,\,$6 $\,\,$ \\
$\,\,$ 1/9$\,\,$ & $\,\,$ 1/3$\,\,$ & $\,\,$ 1 $\,\,$ & $\,\,$3 $\,\,$ \\
$\,\,$ 1/8$\,\,$ & $\,\,$ 1/6$\,\,$ & $\,\,$ 1/3$\,\,$ & $\,\,$ 1  $\,\,$ \\
\end{pmatrix},
\qquad
\lambda_{\max} =
4.1263,
\qquad
CR = 0.0476
\end{equation*}

\begin{equation*}
\mathbf{w}^{EM} =
\begin{pmatrix}
0.578100\\
\color{red} 0.277375\color{black} \\
0.096350\\
0.048175
\end{pmatrix}\end{equation*}
\begin{equation*}
\left[ \frac{{w}^{EM}_i}{{w}^{EM}_j} \right] =
\begin{pmatrix}
$\,\,$ 1 $\,\,$ & $\,\,$\color{red} 2.0842\color{black} $\,\,$ & $\,\,$6$\,\,$ & $\,\,$12$\,\,$ \\
$\,\,$\color{red} 0.4798\color{black} $\,\,$ & $\,\,$ 1 $\,\,$ & $\,\,$\color{red} 2.8788\color{black} $\,\,$ & $\,\,$\color{red} 5.7577\color{black}   $\,\,$ \\
$\,\,$1/6$\,\,$ & $\,\,$\color{red} 0.3474\color{black} $\,\,$ & $\,\,$ 1 $\,\,$ & $\,\,$2 $\,\,$ \\
$\,\,$1/12$\,\,$ & $\,\,$\color{red} 0.1737\color{black} $\,\,$ & $\,\,$1/2$\,\,$ & $\,\,$ 1  $\,\,$ \\
\end{pmatrix},
\end{equation*}

\begin{equation*}
\mathbf{w}^{\prime} =
\begin{pmatrix}
0.571429\\
0.285714\\
0.095238\\
0.047619
\end{pmatrix} =
0.988460\cdot
\begin{pmatrix}
0.578100\\
\color{gr} 0.289050\color{black} \\
0.096350\\
0.048175
\end{pmatrix},
\end{equation*}
\begin{equation*}
\left[ \frac{{w}^{\prime}_i}{{w}^{\prime}_j} \right] =
\begin{pmatrix}
$\,\,$ 1 $\,\,$ & $\,\,$\color{blue} 2\color{black} $\,\,$ & $\,\,$6$\,\,$ & $\,\,$12$\,\,$ \\
$\,\,$\color{blue} 1/2\color{black} $\,\,$ & $\,\,$ 1 $\,\,$ & $\,\,$\color{blue} 3\color{black} $\,\,$ & $\,\,$\color{gr} \color{blue} 6\color{black}   $\,\,$ \\
$\,\,$1/6$\,\,$ & $\,\,$\color{blue} 1/3\color{black} $\,\,$ & $\,\,$ 1 $\,\,$ & $\,\,$2 $\,\,$ \\
$\,\,$1/12$\,\,$ & $\,\,$\color{gr} \color{blue}  1/6\color{black} $\,\,$ & $\,\,$1/2$\,\,$ & $\,\,$ 1  $\,\,$ \\
\end{pmatrix},
\end{equation*}
The ratios calculated from the dominating weight vector give
not only an improved, but a perfect approximation of the original
pairwise comparison matrix in all entries of a row/column.
Examples A.116, A.139, A.162., A.200, A.374 and A.553 have this particular property.
\end{example}


\subsection{Matrices with arbitrary $CR$ inconsistency}
Since the rule of thumb $CR \leq 0.1$ has been applied in a wide range of decision problems
\cite{SubramanianRamanathan2012,VaidyaKumar2006},
its theoretical foundation is debated.
We have considered all the $1\,007\,097$ permutation f{\kern0pt}iltered
pairwise comparison matrices of size $4 \times 4$ and plotted the
frequencies of inef{\kern0pt}f{\kern0pt}icient eigenvector, arithmetic mean of all spanning tree weight vectors (AMAST),
and the weight vector from cosine maximization, as functions of $CR$ inconsistency.
$CR = 0$ represents the consistent case. The upper bound of $CR$ is 3.645
since pairwise comparison matrix
\[
\begin{pmatrix}
   1      &      9       &     1/9      &         9            \\
  1/9     &      1       &     9        &        1/9           \\
   9      &     1/9      &     1        &         9            \\
  1/9     &      9       &    1/9       &         1
\end{pmatrix}
\]
has the largest $\lambda_{\max} = 13.6\dot{6}$, consequently the largest $CR$ inconsistency
\cite{AupetitGenest1993}.


The number of pairwise comparison matrices as a function of $CR$ (on the left in Figure 1)
is similar to the one in Boz\'oki, Rapcs\'ak \cite[Figure 3b]{BozokiRapcsak2008}, but their matrices were
generated randomly.

The right part of Figure 1 shows that the ratio of inef{\kern0pt}f{\kern0pt}icient EM, AMAST and $\cos$ weight vectors is maximal
(29\%; 28\% and 14\%, respectively) at around $CR = 1.2$.
All the three methods provide ef{\kern0pt}f{\kern0pt}icient priority vectors
for matrices with extremely high inconsistency ($CR > 2.6$).

\unitlength 1mm
\begin{center}
\begin{picture}(150,70)
\put(10,10){\resizebox{140mm}{!}{\rotatebox{0}{\includegraphics{abra3.eps}}}}
\put(45,9){(a)}
\put(110,9){(b)}
\put(20,3){\makebox{\textbf{Figure 1.} (a) distribution of inconsistency index $CR$ among $4 \times 4 $ matrices }}
\put(5,-1){\makebox{(b) frequencies of inef{\kern0pt}f{\kern0pt}icient eigenvectors, AMAST and cosine maximization weight vectors }}
\end{picture}
\end{center}
% \ref{example1}


\section{Conclusions}
We have found that three weighting methods, the eigenvector, the arithmetic mean of all
spanning trees's weight vectors and the cosine maximization provide inef{\kern0pt}f{\kern0pt}icient priority
vectors with a small but not negligible frequency if $CR \leq 0.1$. Hundreds of examples indicate that
it is not only a theoretical phenomenon, but it may have ef{\kern0pt}fect on the ranking itself, too.
Our opinion is that inef{\kern0pt}f{\kern0pt}icient priority vectors are not acceptable in any decision problem.
Consequently, the test of ef{\kern0pt}f{\kern0pt}iciency, and, in case of inef{\kern0pt}f{\kern0pt}iciency, f{\kern0pt}inding an ef{\kern0pt}f{\kern0pt}icient dominating
weight vector is necessary.

\section*{Acknowledgements}
Research was supported in part by the Hungarian
Scientif{\kern0pt}ic Research Fund (OTKA) grant no.~K111797.
S.~Boz\'oki acknowledges the support of the J\'anos Bolyai
Research Fellowship of the Hungarian Academy of Sciences
(no.~BO/00154/16).
LEMON -- Library for Ef{\kern0pt}f{\kern0pt}icient Modeling and Optimization in Networks
C++ optimization library (http://lemon.cs.elte.hu) has been used in part
in the calculations.

\begin{thebibliography}{99}
\bibitem{AupetitGenest1993}
Aupetit, B., Genest, C. (1993)
On some useful properties of the Perron eigenvalue of a
positive reciprocal matrix in the context of the analytic hierarchy process.
European Journal of Operational Research
70(2):263--268
% DOI 10.1016/0377-2217(93)90044-N
% http://www.sciencedirect.com/science/article/pii/037722179390044N

\bibitem{BajwaChooWedley2008}
Bajwa, G., Choo, E.U., Wedley, W.C. (2008)
Ef{\kern0pt}fectiveness analysis of deriving priority vectors from reciprocal pairwise comparison matrices.
Asia-Pacif{\kern0pt}ic Journal of Operational Research,
25(3):279--299.
% DOI 10.1142/S0217595908001754
% http://www.worldscientific.com/doi/pdf/10.1142/S0217595908001754

\bibitem{BlanqueroCarrizosaConde2006}
Blanquero, R., Carrizosa, E., Conde, E. (2006)  Inferring
ef{\kern0pt}f{\kern0pt}icient weights from pairwise comparison
matrices. Mathematical Methods of Operations Research
64(2):271--284
% DOI 10.1007/s00186-006-0077-1
% http://link.springer.com/article/10.1007/s00186-006-0077-1#

\bibitem{BozokiFulop2018}
Boz\'oki, S., F\"ul\"op, J. (2018)
Ef{\kern0pt}f{\kern0pt}icient weight vectors from pairwise comparison matrices.
European Journal of Operational Research
 264(2):419-427
% DOI 10.1016/j.ejor.2017.06.033
% http://www.sciencedirect.com/science/article/pii/S0377221717305726

\bibitem{BozokiRapcsak2008}
Boz\'oki, S., Rapcs\'ak, T. (2008)
On Saaty's and Koczkodaj's inconsistencies of pairwise comparison matrices.
Journal of Global Optimization
42(2):157--175.
% DOI 10.1007/s10898-007-9236-z
% https://link.springer.com/article/10.1007%2Fs10898-007-9236-z

\bibitem{BozokiTsyganok2018}
Bozóki, S., Tsyganok, V. ($\geq$ 2018)
The logarithmic least squares optimality of the geometric mean of weight vectors
calculated from all spanning trees for (in)complete pairwise comparison matrices.
Under review,
https://arxiv.org/abs/1701.04265
%    https://arxiv.org/abs/1701.04265
% DOI
%

\bibitem{ChooWedley2004}
Choo, E.U., Wedley, W.C. (2004)
A common framework for deriving preference values from pairwise comparison matrices.
Computers \& Operations Research 31(6):893--908
% DOI 10.1016/S0305-0548(03)00042-X
% http://www.sciencedirect.com/science/article/pii/S030505480300042X

\bibitem{CrawfordWilliams1980}
Crawford, G., Williams, C. (1980)
Analysis of subjective judgment matrices. The Rand Corporation, Of{\kern0pt}f{\kern0pt}ice
of the Secretary of Defense USA, R-2572-AF

\bibitem{CrawfordWilliams1985}
Crawford, G., Williams, C. (1985)
A note on the analysis of subjective judgment matrices.
Journal of Mathematical Psychology
29(4):387--405
% DOI 10.1016/0022-2496(85)90002-1
% http://www.sciencedirect.com/science/article/pii/0022249685900021

\bibitem{deGraan1980}
de Graan, J.G. (1980)
Extensions of the multiple criteria analysis method of T.L.~Saaty.
Presented at EURO IV Conference, Cambridge, July 22-25, 1980

\bibitem{Fedrizzi2013}
Fedrizzi, M. (2013)
Obtaining non-dominated weights from preference relations through norm-induced distances.
Proceedings of the
XXXVII Meeting of the Italian Association for Mathematics Applied to Economic and Social Sciences (AMASES),
Stresa, Italy, September 5-7, 2013.
% https://www.eco.uninsubria.it/site/xxxvii-meeting-amases/

\bibitem{FedrizziBrunelli2010}
Fedrizzi, M., Brunelli, M. (2010)
On the priority vector associated with a reciprocal relation and a pairwise comparison matrix.
Soft Computing 14(6):639--645
% http://link.springer.com/article/10.1007%2Fs00500-009-0432-2

\bibitem{Fichtner1984}
Fichtner, J. (1984)
Some thoughts about the Mathematics of the Analytic Hierarchy Process.
Report 8403,
Universit\"at der Bundeswehr M\"unchen,
Fakult\"at f\"ur Informatik,
Institut f\"ur Angewandte Systemforschung und Operations Research,
Werner-Heisenberg-Weg 39, D-8014 Neubiberg, F.R.G.
1984.

\bibitem{Fichtner1986}
Fichtner, J. (1986)
On deriving priority vectors from matrices of pairwise comparisons.
Socio-Economic Planning Sciences
20(6):341--345
% DOI 10.1016/0038-0121(86)90045-5
% http://www.sciencedirect.com/science/article/pii/0038012186900455

\bibitem{GolanyKress1993}
Golany, B., Kress, M. (1993)
A multicriteria evaluation of methods for obtaining weights from ratio-scale matrices.
European Journal of Operational Research
69(2):210--220
% doi:10.1016/0377-2217(93)90165-J
% http://www.sciencedirect.com/science/article/pii/037722179390165J

\bibitem{KouLin2014}
Kou, G., Lin, C. (2014)
A cosine maximization method for the priority vector derivation in AHP.
European Journal of Operational Research
235(1):225--232
% DOI 10.1016/j.ejor.2013.10.019
% http://www.sciencedirect.com/science/article/pii/S0377221713008424

\bibitem{Lin2007}
Lin, C.-C. (2007)
A revised framework for deriving preference values from pairwise comparison matrices.
European Journal of Operational Research
176(2):1145--1150

\bibitem{LundySirajGreco2017}
Lundy, M., Siraj, S., Greco, S. (2017)
The mathematical equivalence of the ``spanning tree''
and row geometric mean preference vectors and its implications for preference analysis.
European Journal of Operational Research 257(1):197--208
% DOI 10.1016/j.ejor.2016.07.042
% http://www.sciencedirect.com/science/article/pii/S0377221716305975

\bibitem{Rabinowitz1976}
Rabinowitz, G. (1976)
Some comments on measuring world inf{\kern0pt}luence.
Journal of Peace Science
2(1):49--55
% DOI 10.1177/073889427600200104
% https://doi.org/10.1177/073889427600200104
% http://journals.sagepub.com/doi/abs/10.1177/073889427600200104?journalCode=cmpa

\bibitem{Saaty1977}
Saaty, T.L. (1977)
A scaling method for priorities in hierarchical structures.
Journal of Mathematical Psychology
15(3):234--281
% doi:10.1016/0022-2496(77)90033-5
% http://www.sciencedirect.com/science/article/pii/0022249677900335

\bibitem{SirajMikhailovKeane2012a}
Siraj, S., Mikhailov, L., Keane, J.A. (2012)
Enumerating all spanning trees for pairwise comparisons.
Computers \& Operations Research
39(2):191--199
% doi:10.1016/j.cor.2011.03.010
% http://www.sciencedirect.com/science/article/pii/S0305054811000839

\bibitem{SirajMikhailovKeane2012b}
Siraj, S., Mikhailov, L., Keane, J.A. (2012)
Corrigendum to ``Enumerating all spanning trees for pairwise comparisons [Comput. Oper. Res. 39 (2012) 191-199]''.
Computers \& Operations Research
39(9) page 2265
% doi:10.1016/j.cor.2011.11.010
% http://www.sciencedirect.com/science/article/pii/S0305054811003352

\bibitem{SubramanianRamanathan2012}
Subramanian, N., Ramanathan, R. (2012)
A review of applications of Analytic Hierarchy Process in operations management.
International Journal of Production Economics
138(2):215--241
% DOI 10.1016/j.ijpe.2012.03.036
% http://www.sciencedirect.com/science/article/pii/S0925527312001442

\bibitem{Tsyganok2000}
Tsyganok, V. (2000)
Combinatorial method of pairwise comparisons with feedback.
Data Recording, Storage \& Processing
2:92--102 (in Ukrainian)

\bibitem{Tsyganok2010}
Tsyganok, V. (2010)
Investigation of the aggregation ef{\kern0pt}fectiveness of expert estimates obtained by the pairwise comparison method.
Mathematical and Computer Modelling
52(3-4):538--544
% doi: 10.1016/j.mcm.2010.03.052
% http://www.sciencedirect.com/science/article/pii/S0895717710001706

\bibitem{VaidyaKumar2006}
Vaidya, O.S., Kumar, S. (2006)
Analytic hierarchy process: An overview of applications.
European Journal of Operational Research
169(1):1--29
% DOI 10.1016/j.ejor.2004.04.028
% http://www.sciencedirect.com/science/article/pii/S0377221704003054

\end{thebibliography}

\newpage
\appendix
\section*{Online appendix}
\setcounter{section}{0}
\section{Inef{\kern0pt}f{\kern0pt}icient eigenvector}
\input{SubSectionEigenvector-UJ.tex}
\newpage
\section{Inef{\kern0pt}f{\kern0pt}icient $AMAST$ (spanning trees, arithmetic mean)
weight vector}
\input{SubSectionAMAST-UJ.tex}
\newpage
\section{Inef{\kern0pt}f{\kern0pt}icient cosine weight vector}
\input{SubSectionCosinus-UJ.tex}
\end{document}
